import streamlit as st
from groq import Groq
import requests
import io
from PIL import Image

# --- THEME & SPACE BACKGROUND ---
st.set_page_config(page_title="Genis Pro 1.2", page_icon="ðŸš€")

st.markdown("""
    <style>
    .stApp {
        background: radial-gradient(ellipse at bottom, #1B2735 0%, #090A0F 100%);
        color: #ffffff;
    }
    .stApp::before {
        content: "";
        position: absolute;
        top: 0; left: 0; right: 0; bottom: 0;
        background: transparent url('https://www.transparenttextures.com/patterns/stardust.png') repeat;
        opacity: 0.3;
        z-index: -1;
    }
    h1, h2, h3 { color: #00d4ff !important; text-shadow: 0 0 10px #00d4ff; }
    div[data-testid="stChatMessage"] { background-color: rgba(255, 255, 255, 0.05); border-radius: 10px; }
    </style>
    """, unsafe_allow_html=True)

st.title("ðŸš€ Genis Pro 1.2")
st.caption("Developed by BotDevelopmentAI")

# --- CLIENT SETUP ---
client = Groq(api_key=st.secrets["GROQ_API_KEY"])
HF_URL = "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell"
HF_HEADERS = {"Authorization": f"Bearer {st.secrets['HF_TOKEN']}"}

# --- BRAINWASHING & IDENTITY ---
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "system", 
        "content": (
            "You are Genis Pro 1.2. Your company is BotDevelopmentAI. "
            "Never say you are Meta or Llama. If asked for an image, "
            "say you will use 'SmartBot Ludy' to create it."
        )
    }]

# --- IMAGE GENERATOR (SmartBot Ludy) ---
def smartbot_ludy(prompt):
    response = requests.post(HF_URL, headers=HF_HEADERS, json={"inputs": prompt})
    return response.content

# --- CHAT UI ---
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

if prompt := st.chat_input("How can BotDevelopmentAI help you today?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # Check if user wants an image
        if any(x in prompt.lower() for x in ["draw", "image", "generate", "picture"]):
            st.write("Calling SmartBot Ludy... ðŸŽ¨")
            try:
                img_data = smartbot_ludy(prompt)
                img = Image.open(io.BytesIO(img_data))
                st.image(img, caption="Generated by SmartBot Ludy")
                st.session_state.messages.append({"role": "assistant", "content": "Image generated."})
            except:
                st.error("SmartBot Ludy is resting. Try again soon!")
        
        else:
            # TEXT STREAMING (Fixed to prevent JSON spam)
            completion = client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                stream=True,
            )
            
            # Manual streaming loop to capture text ONLY
            full_response = ""
            resp_container = st.empty()
            for chunk in completion:
                content = chunk.choices[0].delta.content
                if content:
                    full_response += content
                    resp_container.markdown(full_response)
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})

with st.sidebar:
    if st.button("Reset Genis Pro"):
        st.session_state.messages = st.session_state.messages[:1]
        st.rerun()
